# ğŸ›¡ï¸ Deep Visionary 

**Vision Transformer â€¢ FastAPI â€¢ Celery â€¢ Redis â€¢ React â€¢ Docker**

A full-stack, production-ready **DeepFake image detection system** powered by a **Vision Transformer (ViT)** model.
The application supports **asynchronous inference**, **real-time frontend polling**, and **fully dockerized deployment**.

---

## ğŸš€ Features

* ğŸ” Vision Transformer (ViT) based DeepFake detection
* âš¡ FastAPI backend with async request handling
* ğŸ§µ Celery + Redis for background inference
* ğŸŒ React (Vite) frontend
* ğŸ³ Fully Dockerized (Backend, Worker, Redis, Frontend)
* ğŸ“¡ Async API (`/predict` â†’ `/result/{task_id}`)
* ğŸ” Proper CORS & Docker networking
* ğŸ“¦ Model persistence using Docker volumes

---

## ğŸ—ï¸ Architecture

```text
Frontend (React)
     |
     | HTTP
     v
FastAPI Backend
     |
     | Async Task
     v
Celery Worker
     |
     | Inference
     v
Vision Transformer Model
     |
     v
Redis (Broker & Results)
```

---

## ğŸ”Œ API Endpoints

### â¤ Predict Image

```http
POST /predict
```

**Request**

* `multipart/form-data`
* Field: `file`

**Response**

```json
{
  "task_id": "abc123"
}
```

---

### â¤ Get Prediction Result

```http
GET /result/{task_id}
```

**Processing**

```json
{ "status": "processing" }
```

**Success**

```json
{
  "status": "done",
  "prediction": {
    "label": "Real",
    "confidence": 0.99
  }
}
```

**Failure**

```json
{ "status": "failed" }
```

---

## ğŸ³ Docker Setup

### Prerequisites

* Docker
* Docker Compose

---

### Build & Run

```bash
docker-compose up --build
```

---

### Access Services

| Service  | URL                                            |
| -------- | ---------------------------------------------- |
| Frontend | [http://localhost:3000](http://localhost:3000) |
| Backend  | [http://localhost:8000](http://localhost:8000) |
| Redis    | redis://localhost:6379                         |

---

## ğŸŒ Docker Networking (Important)

* âŒ `localhost` does NOT work between containers
* âœ… Containers communicate via **service names**

Frontend uses:

```ts
VITE_API_URL=http://backend:8000
```

---

## ğŸ” CORS Configuration

Backend allows frontend access:

```python
allow_origins=["http://localhost:3000"]
```

---

## ğŸ“¦ Model Handling

* Model files are NOT committed to GitHub
* Loaded at startup or from Docker volume

```yaml
volumes:
  - model-data:/app/content/final-vit-model
```

---

## ğŸ§  Why Celery?

* Prevents blocking API requests
* Handles heavy ML inference
* Enables scalable async processing
* Perfect for production ML systems

---

## ğŸ› ï¸ Tech Stack

**Backend**

* FastAPI
* Celery
* Redis
* PyTorch / Transformers

**Frontend**

* React
* Vite
* Tailwind

**DevOps**

* Docker
* Docker Compose

---

## ğŸš€ Deployment Ready

Can be deployed on:

* AWS (EC2 / ECS)
* Google Cloud (GCE / Cloud Run)
* Azure (VM / Containers)

Next steps:

* Cloud deployment
* CI/CD with GitHub Actions

---

## ğŸ‘¨â€ğŸ’» Author

**Muhammad Daniyal Ijaz**
AI / ML Engineer
FastAPI â€¢ Vision Transformers â€¢ Docker â€¢ Cloud

---

## â­ Support

If you find this project useful:

* â­ Star the repository
* ğŸ´ Fork it
* ğŸš€ Deploy it
